{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"../data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2, 3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for layer1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for layer2_W\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for layer1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for layer2_W\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.307691, Train accuracy: 0.107667, val accuracy: 0.112000\n",
      "Epoch 1, Loss: 2.304134, Train accuracy: 0.188333, val accuracy: 0.194000\n",
      "Epoch 2, Loss: 2.304930, Train accuracy: 0.196556, val accuracy: 0.205000\n",
      "Epoch 3, Loss: 2.284791, Train accuracy: 0.196333, val accuracy: 0.205000\n",
      "Epoch 4, Loss: 2.348477, Train accuracy: 0.196222, val accuracy: 0.201000\n",
      "Epoch 5, Loss: 2.296778, Train accuracy: 0.195778, val accuracy: 0.203000\n",
      "Epoch 6, Loss: 2.289093, Train accuracy: 0.195667, val accuracy: 0.204000\n",
      "Epoch 7, Loss: 2.292501, Train accuracy: 0.195556, val accuracy: 0.204000\n",
      "Epoch 8, Loss: 2.263762, Train accuracy: 0.195333, val accuracy: 0.204000\n",
      "Epoch 9, Loss: 2.362354, Train accuracy: 0.195667, val accuracy: 0.205000\n",
      "Epoch 10, Loss: 2.240366, Train accuracy: 0.195444, val accuracy: 0.204000\n",
      "Epoch 11, Loss: 2.305230, Train accuracy: 0.195222, val accuracy: 0.204000\n",
      "Epoch 12, Loss: 2.312209, Train accuracy: 0.195667, val accuracy: 0.204000\n",
      "Epoch 13, Loss: 2.345693, Train accuracy: 0.195556, val accuracy: 0.204000\n",
      "Epoch 14, Loss: 2.278949, Train accuracy: 0.195333, val accuracy: 0.204000\n",
      "Epoch 15, Loss: 2.227063, Train accuracy: 0.195333, val accuracy: 0.204000\n",
      "Epoch 16, Loss: 2.269648, Train accuracy: 0.195444, val accuracy: 0.204000\n",
      "Epoch 17, Loss: 2.241361, Train accuracy: 0.195333, val accuracy: 0.204000\n",
      "Epoch 18, Loss: 2.187355, Train accuracy: 0.195444, val accuracy: 0.205000\n",
      "Epoch 19, Loss: 2.284011, Train accuracy: 0.195556, val accuracy: 0.204000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18610b78860>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.307665, Train accuracy: 0.149222, val accuracy: 0.141000\n",
      "Epoch 1, Loss: 2.303397, Train accuracy: 0.188333, val accuracy: 0.185000\n",
      "Epoch 2, Loss: 2.309555, Train accuracy: 0.195667, val accuracy: 0.203000\n",
      "Epoch 3, Loss: 2.355164, Train accuracy: 0.196667, val accuracy: 0.204000\n",
      "Epoch 4, Loss: 2.261761, Train accuracy: 0.197111, val accuracy: 0.202000\n",
      "Epoch 5, Loss: 2.332469, Train accuracy: 0.196889, val accuracy: 0.204000\n",
      "Epoch 6, Loss: 2.206761, Train accuracy: 0.196667, val accuracy: 0.204000\n",
      "Epoch 7, Loss: 2.335331, Train accuracy: 0.197111, val accuracy: 0.205000\n",
      "Epoch 8, Loss: 2.372841, Train accuracy: 0.196889, val accuracy: 0.205000\n",
      "Epoch 9, Loss: 2.231308, Train accuracy: 0.196889, val accuracy: 0.204000\n",
      "Epoch 10, Loss: 2.306652, Train accuracy: 0.197333, val accuracy: 0.204000\n",
      "Epoch 11, Loss: 2.279988, Train accuracy: 0.197000, val accuracy: 0.204000\n",
      "Epoch 12, Loss: 2.327024, Train accuracy: 0.197222, val accuracy: 0.204000\n",
      "Epoch 13, Loss: 2.282093, Train accuracy: 0.197111, val accuracy: 0.204000\n",
      "Epoch 14, Loss: 2.255534, Train accuracy: 0.197000, val accuracy: 0.204000\n",
      "Epoch 15, Loss: 2.326267, Train accuracy: 0.197000, val accuracy: 0.204000\n",
      "Epoch 16, Loss: 2.269815, Train accuracy: 0.197333, val accuracy: 0.204000\n",
      "Epoch 17, Loss: 2.272495, Train accuracy: 0.197111, val accuracy: 0.204000\n",
      "Epoch 18, Loss: 2.295318, Train accuracy: 0.197222, val accuracy: 0.204000\n",
      "Epoch 19, Loss: 2.347106, Train accuracy: 0.197556, val accuracy: 0.204000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.328302, Train accuracy: 0.146667, val accuracy: 0.135000\n",
      "Epoch 1, Loss: 2.324201, Train accuracy: 0.148111, val accuracy: 0.139000\n",
      "Epoch 2, Loss: 2.320900, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 3, Loss: 2.317785, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 4, Loss: 2.315371, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 5, Loss: 2.313386, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 6, Loss: 2.311648, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 7, Loss: 2.310196, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 8, Loss: 2.309241, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 9, Loss: 2.307548, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 10, Loss: 2.307232, Train accuracy: 0.149000, val accuracy: 0.138000\n",
      "Epoch 11, Loss: 2.306531, Train accuracy: 0.149778, val accuracy: 0.142000\n",
      "Epoch 12, Loss: 2.306022, Train accuracy: 0.152000, val accuracy: 0.145000\n",
      "Epoch 13, Loss: 2.304922, Train accuracy: 0.157556, val accuracy: 0.144000\n",
      "Epoch 14, Loss: 2.304760, Train accuracy: 0.162667, val accuracy: 0.142000\n",
      "Epoch 15, Loss: 2.304799, Train accuracy: 0.169333, val accuracy: 0.146000\n",
      "Epoch 16, Loss: 2.304044, Train accuracy: 0.172333, val accuracy: 0.164000\n",
      "Epoch 17, Loss: 2.303692, Train accuracy: 0.176889, val accuracy: 0.176000\n",
      "Epoch 18, Loss: 2.302333, Train accuracy: 0.181556, val accuracy: 0.184000\n",
      "Epoch 19, Loss: 2.304181, Train accuracy: 0.182444, val accuracy: 0.184000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.331396, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Epoch 1, Loss: 2.327265, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Epoch 2, Loss: 2.323907, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Epoch 3, Loss: 2.320646, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Epoch 4, Loss: 2.312516, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Epoch 5, Loss: 2.314508, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Epoch 6, Loss: 2.284937, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 7, Loss: 2.202796, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 8, Loss: 2.332546, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 9, Loss: 1.984269, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 10, Loss: 1.831194, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 11, Loss: 1.919116, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 12, Loss: 2.193295, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 13, Loss: 1.857043, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 14, Loss: 1.784641, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 15, Loss: 1.479517, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 16, Loss: 2.399917, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 17, Loss: 2.340523, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 18, Loss: 1.978345, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 19, Loss: 2.364687, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 20, Loss: 1.536531, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 21, Loss: 2.078691, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 22, Loss: 2.441479, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 23, Loss: 1.544641, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 24, Loss: 1.908295, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 25, Loss: 1.930052, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 26, Loss: 1.478086, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 27, Loss: 1.436580, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 28, Loss: 1.993014, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 29, Loss: 1.693940, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 30, Loss: 1.631278, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 31, Loss: 2.094490, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 32, Loss: 2.057523, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 33, Loss: 1.024284, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 34, Loss: 1.950225, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 35, Loss: 2.033256, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 36, Loss: 1.566326, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 37, Loss: 1.499016, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 38, Loss: 1.871726, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 39, Loss: 1.441289, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 40, Loss: 1.292728, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 41, Loss: 1.752583, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 42, Loss: 1.779579, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 43, Loss: 1.416387, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 44, Loss: 2.005514, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 45, Loss: 2.084282, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 46, Loss: 1.351080, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 47, Loss: 1.266605, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 48, Loss: 0.954492, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 49, Loss: 0.716557, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 50, Loss: 1.512300, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 51, Loss: 1.658117, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 52, Loss: 1.465972, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 53, Loss: 1.440554, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 54, Loss: 0.974906, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 55, Loss: 1.335640, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 56, Loss: 1.833365, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 57, Loss: 1.601465, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 58, Loss: 1.087183, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 59, Loss: 1.412384, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 60, Loss: 1.718686, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 61, Loss: 1.919568, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 62, Loss: 1.700922, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 63, Loss: 1.400817, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 64, Loss: 0.984466, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 65, Loss: 0.965487, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 66, Loss: 1.587063, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 67, Loss: 1.418150, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 68, Loss: 1.331224, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 69, Loss: 1.601192, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 70, Loss: 1.485163, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 71, Loss: 1.812462, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 72, Loss: 1.621700, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 73, Loss: 1.204349, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 74, Loss: 1.748497, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 75, Loss: 1.263450, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 76, Loss: 1.779212, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 77, Loss: 1.227262, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 78, Loss: 1.277022, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 79, Loss: 1.243966, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 80, Loss: 0.999014, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 81, Loss: 1.370499, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 82, Loss: 1.730235, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 83, Loss: 1.390952, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 84, Loss: 1.205973, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 85, Loss: 1.613774, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 86, Loss: 1.612008, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 87, Loss: 1.562498, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 88, Loss: 1.961431, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 89, Loss: 1.260367, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 90, Loss: 1.746754, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 91, Loss: 1.282254, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 92, Loss: 1.886621, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 93, Loss: 1.298900, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 94, Loss: 1.327359, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 95, Loss: 1.738390, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 96, Loss: 1.160887, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 97, Loss: 1.574532, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 98, Loss: 1.367297, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 99, Loss: 1.352783, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 100, Loss: 1.894135, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 101, Loss: 1.145438, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 102, Loss: 1.563833, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 103, Loss: 1.206239, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 104, Loss: 1.268104, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 105, Loss: 1.580365, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 106, Loss: 1.874381, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 107, Loss: 0.896847, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 108, Loss: 1.465930, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 109, Loss: 1.107696, Train accuracy: 0.933333, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, Loss: 1.258996, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 111, Loss: 1.622160, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 112, Loss: 0.991641, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 113, Loss: 1.226367, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 114, Loss: 1.176572, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 115, Loss: 1.259798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 116, Loss: 1.505560, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 117, Loss: 1.557500, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 118, Loss: 1.286847, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 119, Loss: 1.702245, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 120, Loss: 1.480443, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 121, Loss: 1.482417, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 122, Loss: 1.119688, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 123, Loss: 1.349265, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 124, Loss: 1.335986, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 125, Loss: 1.353222, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 126, Loss: 1.139256, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 127, Loss: 1.303899, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 128, Loss: 1.177165, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 129, Loss: 1.128937, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 130, Loss: 1.207409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 131, Loss: 1.557162, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 132, Loss: 1.248073, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 133, Loss: 1.163258, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 134, Loss: 1.696851, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 135, Loss: 1.080335, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 136, Loss: 1.548343, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 137, Loss: 1.264934, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 138, Loss: 1.253103, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 139, Loss: 1.208046, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 140, Loss: 1.320130, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 141, Loss: 1.191310, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 142, Loss: 1.174883, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 143, Loss: 1.582263, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 144, Loss: 1.408412, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 145, Loss: 1.214843, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 146, Loss: 1.025452, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 147, Loss: 1.322252, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 148, Loss: 1.454514, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 149, Loss: 1.249132, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.301398, Train accuracy: 0.266667, val accuracy: 0.200000\n",
      "Epoch 1, Loss: 2.299164, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Epoch 2, Loss: 2.262715, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 3, Loss: 1.555040, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 4, Loss: 2.528855, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 5, Loss: 1.477000, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 6, Loss: 0.190655, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 7, Loss: 2.208521, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 8, Loss: 2.249035, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 9, Loss: 2.275441, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 10, Loss: 2.141262, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 11, Loss: 2.019227, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 12, Loss: 0.545081, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 13, Loss: 2.285358, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 14, Loss: 1.324950, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Epoch 15, Loss: 0.279049, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 16, Loss: 0.148822, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 17, Loss: 0.005629, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 18, Loss: 1.362997, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 19, Loss: 0.162234, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-6)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=2)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.157694, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1, Loss: 2.263316, Train accuracy: 0.196556, val accuracy: 0.206000\n",
      "Epoch 2, Loss: 2.262331, Train accuracy: 0.196556, val accuracy: 0.206000\n",
      "Epoch 3, Loss: 2.092710, Train accuracy: 0.213889, val accuracy: 0.223000\n",
      "Epoch 4, Loss: 2.023830, Train accuracy: 0.277111, val accuracy: 0.283000\n",
      "Epoch 5, Loss: 1.731888, Train accuracy: 0.332111, val accuracy: 0.344000\n",
      "Epoch 6, Loss: 1.894168, Train accuracy: 0.393111, val accuracy: 0.391000\n",
      "Epoch 7, Loss: 1.655648, Train accuracy: 0.423333, val accuracy: 0.425000\n",
      "Epoch 8, Loss: 1.593301, Train accuracy: 0.456778, val accuracy: 0.454000\n",
      "Epoch 9, Loss: 1.547670, Train accuracy: 0.501667, val accuracy: 0.497000\n",
      "Epoch 10, Loss: 1.389713, Train accuracy: 0.536111, val accuracy: 0.525000\n",
      "Epoch 11, Loss: 1.669607, Train accuracy: 0.565889, val accuracy: 0.550000\n",
      "Epoch 12, Loss: 1.264176, Train accuracy: 0.577000, val accuracy: 0.556000\n",
      "Epoch 13, Loss: 1.377082, Train accuracy: 0.603111, val accuracy: 0.580000\n",
      "Epoch 14, Loss: 1.044346, Train accuracy: 0.621444, val accuracy: 0.607000\n",
      "Epoch 15, Loss: 1.591372, Train accuracy: 0.629333, val accuracy: 0.606000\n",
      "Epoch 16, Loss: 1.296853, Train accuracy: 0.637556, val accuracy: 0.628000\n",
      "Epoch 17, Loss: 1.377265, Train accuracy: 0.649111, val accuracy: 0.632000\n",
      "Epoch 18, Loss: 1.317208, Train accuracy: 0.652778, val accuracy: 0.646000\n",
      "Epoch 19, Loss: 1.308731, Train accuracy: 0.663556, val accuracy: 0.644000\n",
      "Epoch 20, Loss: 1.134319, Train accuracy: 0.669222, val accuracy: 0.658000\n",
      "Epoch 21, Loss: 1.102301, Train accuracy: 0.671667, val accuracy: 0.657000\n",
      "Epoch 22, Loss: 1.060641, Train accuracy: 0.677222, val accuracy: 0.664000\n",
      "Epoch 23, Loss: 1.170619, Train accuracy: 0.682000, val accuracy: 0.665000\n",
      "Epoch 24, Loss: 1.379821, Train accuracy: 0.682667, val accuracy: 0.669000\n",
      "Epoch 25, Loss: 1.215858, Train accuracy: 0.685333, val accuracy: 0.676000\n",
      "Epoch 26, Loss: 0.950825, Train accuracy: 0.690444, val accuracy: 0.676000\n",
      "Epoch 27, Loss: 0.998926, Train accuracy: 0.691889, val accuracy: 0.676000\n",
      "Epoch 28, Loss: 1.180077, Train accuracy: 0.693222, val accuracy: 0.676000\n",
      "Epoch 29, Loss: 1.309403, Train accuracy: 0.696667, val accuracy: 0.679000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=128, reg=1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), num_epochs=30, learning_rate=1e-2, learning_rate_decay=0.92, batch_size=64)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.630000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.244367, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1, Loss: 2.239639, Train accuracy: 0.196556, val accuracy: 0.206000\n",
      "Epoch 2, Loss: 2.064170, Train accuracy: 0.198778, val accuracy: 0.209000\n",
      "Epoch 3, Loss: 2.066733, Train accuracy: 0.248000, val accuracy: 0.258000\n",
      "Epoch 4, Loss: 1.775135, Train accuracy: 0.298778, val accuracy: 0.303000\n",
      "Epoch 5, Loss: 1.927187, Train accuracy: 0.361556, val accuracy: 0.355000\n",
      "Epoch 6, Loss: 1.656005, Train accuracy: 0.390556, val accuracy: 0.389000\n",
      "Epoch 7, Loss: 1.605396, Train accuracy: 0.446778, val accuracy: 0.441000\n",
      "Epoch 8, Loss: 1.320720, Train accuracy: 0.499222, val accuracy: 0.493000\n",
      "Epoch 9, Loss: 1.477407, Train accuracy: 0.543222, val accuracy: 0.533000\n",
      "Epoch 10, Loss: 1.402623, Train accuracy: 0.559333, val accuracy: 0.542000\n",
      "Epoch 11, Loss: 1.494254, Train accuracy: 0.588000, val accuracy: 0.581000\n",
      "Epoch 12, Loss: 1.306737, Train accuracy: 0.600111, val accuracy: 0.586000\n",
      "Epoch 13, Loss: 1.166882, Train accuracy: 0.621778, val accuracy: 0.610000\n",
      "Epoch 14, Loss: 1.357363, Train accuracy: 0.634444, val accuracy: 0.615000\n",
      "Epoch 15, Loss: 1.518043, Train accuracy: 0.642222, val accuracy: 0.628000\n",
      "Epoch 16, Loss: 1.283772, Train accuracy: 0.653222, val accuracy: 0.641000\n",
      "Epoch 17, Loss: 1.339225, Train accuracy: 0.661333, val accuracy: 0.657000\n",
      "Epoch 18, Loss: 1.483123, Train accuracy: 0.672333, val accuracy: 0.659000\n",
      "Epoch 19, Loss: 1.221460, Train accuracy: 0.673889, val accuracy: 0.665000\n",
      "Epoch 20, Loss: 1.207462, Train accuracy: 0.679889, val accuracy: 0.672000\n",
      "Epoch 21, Loss: 0.900619, Train accuracy: 0.684778, val accuracy: 0.678000\n",
      "Epoch 22, Loss: 0.970311, Train accuracy: 0.691333, val accuracy: 0.684000\n",
      "Epoch 23, Loss: 1.384463, Train accuracy: 0.693111, val accuracy: 0.679000\n",
      "Epoch 24, Loss: 0.862798, Train accuracy: 0.694889, val accuracy: 0.685000\n",
      "Epoch 25, Loss: 1.182333, Train accuracy: 0.697333, val accuracy: 0.690000\n",
      "Epoch 26, Loss: 0.802478, Train accuracy: 0.699444, val accuracy: 0.689000\n",
      "Epoch 27, Loss: 0.941121, Train accuracy: 0.701000, val accuracy: 0.690000\n",
      "Epoch 28, Loss: 0.977535, Train accuracy: 0.701889, val accuracy: 0.693000\n",
      "Epoch 29, Loss: 1.213042, Train accuracy: 0.702889, val accuracy: 0.699000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=254, reg=1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), num_epochs=30, learning_rate=1e-2, learning_rate_decay=0.92, batch_size=64)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.644000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
